{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d19c51d4",
   "metadata": {},
   "source": [
    "# Importing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2c240",
   "metadata": {},
   "source": [
    "Huge credits to Chris10M on github!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1a157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel executable: /Users/sarath/Downloads/Projects/camhack/Vision/armVenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Kernel executable: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54fde115",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarath/Downloads/Projects/camhack/Vision/armVenv/lib/python3.11/site-packages/face_recognition_models/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "from triggerModel import EyeTrigger\n",
    "\n",
    "torch_weights_path = '/Users/sarath/Downloads/Projects/camhack/Vision/Model Deployment/torch_weights.pth'\n",
    "torch_blueprint = \"my_model.onnx\"\n",
    "landmark_detection_path = \"/Users/sarath/Downloads/Projects/camhack/Vision/open-eye-detector/models/68_face_landmarks_predictor.dat\"\n",
    "triggerModel = EyeTrigger(torch_blueprint, torch_weights_path, landmark_detection_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd4d19",
   "metadata": {},
   "source": [
    "## Side Quest: Port model from `keras` to `torch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901b1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import torch\n",
    "from onnx2pytorch import ConvertModel\n",
    "import tf2onnx \n",
    "import onnx\n",
    "from tensorflow import TensorSpec, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e528e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = \"/Users/sarath/Downloads/Projects/camhack/Vision/open-eye-detector/models/weights.149-0.01.hdf5\"\n",
    "model = load_model(weights_path, compile = False)\n",
    "input_shape = (1,10,20,1)\n",
    "spec = (TensorSpec(input_shape, float32, name=\"input\"),)\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model,input_signature= spec, opset=13)\n",
    "\n",
    "with open(\"my_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eda9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"my_model.onnx\")\n",
    "pytorch_model = ConvertModel(onnx_model)\n",
    "pytorch_model.eval()\n",
    "\n",
    "output_pytorch_path = '/Users/sarath/Downloads/Projects/camhack/Vision/Model Deployment/torch_weights.pth'\n",
    "torch.save(pytorch_model.state_dict(), output_pytorch_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ba947",
   "metadata": {},
   "source": [
    "# Inference Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f745ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from cameraController import CameraController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b24aff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-02 12:28:26.471 Python[34207:15059032] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      9\u001b[39m     frameData = controller.getFrame()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mtriggerModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meyesOpen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mframeData\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cv.waitKey(\u001b[32m1\u001b[39m) & \u001b[32m0xFF\u001b[39m == \u001b[38;5;28mord\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mq\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projects/camhack/Vision/Model Deployment/triggerModel.py:66\u001b[39m, in \u001b[36mEyeTrigger.eyesOpen\u001b[39m\u001b[34m(self, frame, rgb_img, hratio, wratio)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meyesOpen\u001b[39m(\u001b[38;5;28mself\u001b[39m, frame: ndarray, rgb_img: ndarray, hratio, wratio) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     face_locations = \u001b[43mface_recognition\u001b[49m\u001b[43m.\u001b[49m\u001b[43mface_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhog\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_locations): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     70\u001b[39m     top, right, bottom, left = face_locations[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projects/camhack/Vision/armVenv/lib/python3.11/site-packages/face_recognition/api.py:121\u001b[39m, in \u001b[36mface_locations\u001b[39m\u001b[34m(img, number_of_times_to_upsample, model)\u001b[39m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m _raw_face_locations(img, number_of_times_to_upsample, \u001b[33m\"\u001b[39m\u001b[33mcnn\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [_trim_css_to_bounds(_rect_to_css(face), img.shape) \u001b[38;5;28;01mfor\u001b[39;00m face \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_raw_face_locations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/Projects/camhack/Vision/armVenv/lib/python3.11/site-packages/face_recognition/api.py:105\u001b[39m, in \u001b[36m_raw_face_locations\u001b[39m\u001b[34m(img, number_of_times_to_upsample, model)\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cnn_face_detector(img, number_of_times_to_upsample)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mface_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_times_to_upsample\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "cam = cv.VideoCapture(1)\n",
    "\n",
    "if not cam.isOpened():\n",
    "    raise EnvironmentError(\"Camera was not able to be opened.\")\n",
    "\n",
    "controller = CameraController(cam)\n",
    "try:\n",
    "    while True:\n",
    "        frameData = controller.getFrame()\n",
    "        print(triggerModel.eyesOpen(*frameData))\n",
    "\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "finally:\n",
    "    cam.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f339f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_arm_kernel",
   "language": "python",
   "name": "py_arm_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
